#!/usr/bin/env python3

import urllib.request as urlreq
import sys, re, codecs

help_str = '''
This is the help section for {}

Make sure to use the whole url such as:

http://www.google.com

ther will be more info here soon
'''.format(sys.argv[0])

# set regex to distill <a href> URL's 
findlink = re.compile(r'\s+?\S+?[^\<a]+?<a href="([^"]+).*')

user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36"

def main(url):

    # attempt to call the user given URL to look for links
    try:
        html = urlreq.urlopen(url)

    except ValueError:
        print('Invalid URL')
        print('Use full url such as: https://www.google.com')

    except:
        print('Exception occurred! see exception info below\n')
        print(sys.exc_info())

    # search for URL's in webpage
    for line in html:
        rawline = line.decode('unicode_escape')
        matchobj = findlink.match(rawline)

        if matchobj:
            print('***************MATCH FOUND****************')
            link = rawline[matchobj.start(1):matchobj.end(1)]
            # link is the extracted link
            print(link)

        # maybe save found links to a file for later comparison

if __name__ == '__main__':
    
    # program INIT
    if len(sys.argv) < 2:
        # usage string if not enough arguments
        print('Usage: {} <parent url to scan>'.format(sys.argv[0]))
        print('Enter {} --help for more info'.format(sys.argv[0]))
        sys.exit()

    elif '--help' in sys.argv:
        print(help_str)
        sys.exit()

    else:
        # save user given url to a variable for further processing
        url = sys.argv[1]
        urlobj = re.match(r'[^.]+\.([^.]+\.[^\\]+)', url)
        rooturl = url[urlobj.start(1):urlobj.end(1)]

        main(url)
